{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equivariant Neural Field (ENF) Training\n",
    "\n",
    "This notebook implements training for an Equivariant Neural Field model. ENFs are a type of neural field that respects certain symmetries in the data, making them particularly effective for image representation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import math\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import ml_collections\n",
    "import torch\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import orbax.checkpoint as ocp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "\n",
    "from typing import Callable, Union, Any, Sequence\n",
    "\n",
    "# Set environment to use GPU\n",
    "os.environ['JAX_PLATFORM_NAME'] = 'gpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Define the configuration for the model, dataset, and training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define config\n",
    "config = ml_collections.ConfigDict()\n",
    "config.seed = 68\n",
    "config.debug = False\n",
    "\n",
    "# Define the ENF model parameters\n",
    "config.enf = ml_collections.ConfigDict()\n",
    "config.enf.num_in = 2           # Images are 2D\n",
    "config.enf.num_out = 3          # RGB images = 3 channels, grayscale = 1\n",
    "config.enf.num_hidden = 128\n",
    "config.enf.num_heads = 3\n",
    "config.enf.att_dim = 128\n",
    "config.enf.num_latents = 4\n",
    "config.enf.latent_dim = 32\n",
    "config.enf.freq_multiplier_query = 1.0 \n",
    "config.enf.freq_multiplier_value = 2.0 \n",
    "config.enf.k_nearest = 4\n",
    "config.enf.bi_invariant = \"translation\"  # Choose between translation and roto_translation_2d\n",
    "\n",
    "# Dataset config\n",
    "config.dataset = ml_collections.ConfigDict()\n",
    "config.dataset.path = \"./data\"\n",
    "config.dataset.name = \"FIGURE\"           # Choose between cifar10 and FIGURE\n",
    "config.dataset.num_signals_train = 1000\n",
    "config.dataset.num_signals_test = 1000\n",
    "config.dataset.batch_size = 32\n",
    "config.dataset.num_workers = 8\n",
    "\n",
    "# Specific FIGURE dataset parameters\n",
    "config.dataset.figure_type = \"FIGURE-Shape-B\"  # Choose between FIGURE-Shape-B and FIGURE-Shape-CB\n",
    "config.dataset.swap_bias = False               # Mainly interesting for down-stream tasks\n",
    "config.dataset.color_consistency = 0.9\n",
    "\n",
    "# Optimizer config\n",
    "config.optim = ml_collections.ConfigDict()\n",
    "config.optim.lr_enf = 5e-4\n",
    "config.optim.inner_lr_c = 15.\n",
    "config.optim.inner_lr_p = 0.\n",
    "config.optim.inner_lr_g = 0.\n",
    "config.optim.inner_steps = 3\n",
    "\n",
    "# Training config\n",
    "config.train = ml_collections.ConfigDict()\n",
    "config.train.num_epochs = 5000\n",
    "config.train.log_interval = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_numpy(image):\n",
    "    return np.array(image, dtype=np.float32) / 255\n",
    "\n",
    "\n",
    "def numpy_collate(batch: Union[np.ndarray, Sequence[Any], Any]):\n",
    "    \"\"\"\n",
    "    TODO: this might be a repeat, maybe it's ok to make it special for shapes, but needs a check\n",
    "    Collate function for numpy arrays.\n",
    "\n",
    "    This function acts as replacement to the standard PyTorch-tensor collate function in PyTorch DataLoader.\n",
    "\n",
    "    Args:\n",
    "        batch: Batch of data. Can be a numpy array, a list of numpy arrays, or nested lists of numpy arrays.\n",
    "\n",
    "    Returns:\n",
    "        Batch of data as (potential list or tuple of) numpy array(s).\n",
    "    \"\"\"\n",
    "    if isinstance(batch, np.ndarray):\n",
    "        return batch\n",
    "    elif isinstance(batch[0], np.ndarray):\n",
    "        return np.stack(batch)\n",
    "    elif isinstance(batch[0], (tuple, list)):\n",
    "        transposed = zip(*batch)\n",
    "        return [numpy_collate(samples) for samples in transposed]\n",
    "    else:\n",
    "        return np.array(batch)\n",
    "    \n",
    "\n",
    "def get_dataset(dataset_cfg):\n",
    "    \"\"\" Function which gets the dataset based on the dataset config. For now it only supports CIFAR10 and the FIGURE dataset.\"\"\"\n",
    "\n",
    "    if dataset_cfg.name == \"cifar10\":\n",
    "        from torchvision.datasets import CIFAR10\n",
    "\n",
    "        transform = torchvision.transforms.Compose([image_to_numpy])\n",
    "        train_dset = torchvision.datasets.CIFAR10(root=dataset_cfg.path, train=1, transform=transform, download=1)\n",
    "        test_dset = torchvision.datasets.CIFAR10(root=dataset_cfg.path, train=0, transform=transform, download=1)\n",
    "    elif dataset_cfg.name == \"FIGURE\":\n",
    "        from datasets.figure_dset import FigureDataset\n",
    "\n",
    "        transform = torchvision.transforms.Compose([image_to_numpy, lambda x: x.transpose(1, 2, 0)])\n",
    "        train_dset = FigureDataset(\"FIGURE-Shape-B\", split=\"train\", color_consistency=0.9, transform=transform, download=True)  \n",
    "\n",
    "        if dataset_cfg.swap_bias:\n",
    "            test_dset = FigureDataset(\"FIGURE-Shape-CB\", split=\"test-bias\", color_consistency=0.9, transform=transform, download=True)\n",
    "        else:\n",
    "            test_dset = FigureDataset(\"FIGURE-Shape-B\", split=\"test\", color_consistency=0.9, transform=transform, download=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset name: {dataset_cfg.name}\")\n",
    "    \n",
    "    return train_dset, test_dset\n",
    "\n",
    "\n",
    "def get_dataloader(dataset_cfg, shuffle_train=True):\n",
    "    \"\"\" Function which gets the dataloader based on the dataset config. \"\"\"\n",
    "\n",
    "    train_dset, test_dset = get_dataset(dataset_cfg)\n",
    "    \n",
    "    if dataset_cfg.num_signals_train != -1:\n",
    "        train_dset = data.Subset(train_dset, np.arange(0, dataset_cfg.num_signals_train))\n",
    "    if dataset_cfg.num_signals_test != -1:\n",
    "        test_dset = data.Subset(test_dset, np.arange(0, dataset_cfg.num_signals_test))\n",
    "\n",
    "    train_loader = data.DataLoader(\n",
    "        train_dset,\n",
    "        batch_size=dataset_cfg.batch_size,\n",
    "        shuffle=shuffle_train,\n",
    "        num_workers=dataset_cfg.num_workers,\n",
    "        collate_fn=numpy_collate,\n",
    "        persistent_workers=False,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    test_loader = data.DataLoader(\n",
    "        test_dset,\n",
    "        batch_size=dataset_cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=dataset_cfg.num_workers,\n",
    "        collate_fn=numpy_collate,\n",
    "        persistent_workers=False,\n",
    "        drop_last=True\n",
    "    )\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "### Positional embedding\n",
    "\n",
    "The positional embedding is a key component that transforms spatial coordinates into a higher-dimensional representation. The mathematical formula is:\n",
    "\n",
    "1. First, scale the input coordinates: $\\pi(x + 1)$\n",
    "2. Project to a lower dimension with random weights: $e = W \\cdot \\pi(x + 1)$ where $W \\sim \\mathcal{N}(0, \\text{freq})$\n",
    "3. Apply sinusoidal encoding: $\\sin([x, e, e + \\pi/2])$\n",
    "4. Project to final embedding dimension: $\\text{PosEmb}(x) = W_{\\text{out}} \\cdot \\sin([x, e, e + \\pi/2])$\n",
    "\n",
    "This embedding helps the model capture spatial relationships at different frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PosEmb(nn.Module):\n",
    "    embedding_dim: int\n",
    "    freq: float\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, coords):\n",
    "        emb = nn.Dense(self.embedding_dim // 2, kernel_init=nn.initializers.normal(self.freq), use_bias=False)(\n",
    "            jnp.pi * (coords + 1))\n",
    "        return nn.Dense(self.embedding_dim)(jnp.sin(jnp.concatenate([coords, emb, emb + jnp.pi / 2.0], axis=-1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the positional embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the positional embedding for different frequencies\n",
    "freqs = [1.0, 5.0, 20.0]\n",
    "posemb = [PosEmb(128, freq) for freq in freqs]\n",
    "\n",
    "# Create a grid of coordinates\n",
    "grid = jnp.stack(jnp.meshgrid(jnp.linspace(-1, 1, 100), jnp.linspace(-1, 1, 100)), axis=-1)\n",
    "grid = jnp.reshape(grid, (-1, 2))\n",
    "grid = jnp.repeat(grid[None, ...], 1, axis=0)\n",
    "params = [posemb[i].init(jax.random.PRNGKey(i), grid) for i in range(len(posemb))]\n",
    "out = [posemb[i].apply(params[i], grid) for i in range(len(posemb))]\n",
    "\n",
    "# Plot the output for each frequency\n",
    "plt.figure(figsize=(15, 4))\n",
    "for i in range(len(posemb)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(jnp.mean(out[i][0].reshape(100, 100, -1), axis=-1)) # average over the embedding dimension\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Frequency: {freqs[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the bi-invariant functions\n",
    "\n",
    "Bi-invariant functions are crucial for ensuring equivariance in neural fields. They transform input coordinates and latent poses into representations that respect certain symmetries:\n",
    "\n",
    "1. **Translation Bi-invariant**:\n",
    "   - Formula: $\\text{BI}_{\\text{trans}}(x, p) = x - p$\n",
    "   - This creates a representation that is invariant to global translations of both input coordinates and latent poses.\n",
    "\n",
    "2. **Roto-Translation Bi-invariant (2D)**:\n",
    "   - For input coordinates $x \\in \\mathbb{R}^2$ and latent poses $p = (p_{\\text{pos}}, \\theta) \\in \\mathbb{R}^2 \\times \\mathbb{R}$:\n",
    "   - First compute relative position: $\\Delta x = x - p_{\\text{pos}}$\n",
    "   - Then rotate by $-\\theta$ to get invariant representation:\n",
    "     - $\\text{BI}_{\\text{roto-trans}}(x, p)_1 = \\Delta x_1 \\cos(\\theta) + \\Delta x_2 \\sin(\\theta)$\n",
    "     - $\\text{BI}_{\\text{roto-trans}}(x, p)_2 = -\\Delta x_1 \\sin(\\theta) + \\Delta x_2 \\cos(\\theta)$\n",
    "   - This creates a representation that is invariant to both translations and rotations.\n",
    "\n",
    "These bi-invariants ensure that the neural field's predictions remain consistent under the corresponding transformations of the input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bi_invariant(name: str):\n",
    "    \"\"\" Get the bi-invariant function by name. Currently supports 'translation' and 'roto_translation_2d'\"\"\"\n",
    "    \n",
    "    if name == \"translation\":\n",
    "        return TranslationBI()\n",
    "    elif name == \"roto_translation_2d\":\n",
    "        return RotoTranslationBI2D()\n",
    "    else:\n",
    "        raise ValueError(f\"Bi-invariant {name} not found.\")\n",
    "\n",
    "\n",
    "class TranslationBI:   \n",
    "    def __call__(self, x: jnp.ndarray, p: jnp.ndarray) -> jnp.ndarray:\n",
    "        \"\"\"Compute the translation equivariant bi-invariant for ND data.\n",
    "        \n",
    "        Args:\n",
    "            x: The input data. Shape (batch_size, num_coords, coord_dim).\n",
    "            p: The latent poses. Shape (batch_size, num_latents, coord_dim).\n",
    "        \"\"\"\n",
    "        return x[:, :, None, :] - p[:, None, :, :]\n",
    "\n",
    "\n",
    "class RotoTranslationBI2D:\n",
    "    def __call__(self, x: jnp.ndarray, p: jnp.ndarray) -> jnp.ndarray:\n",
    "        \"\"\" Compute roto-translation bi-invariant for 2D data. This assumes the input coordinates are\n",
    "        2D, i.e. do not include the orientation. The latents include orientation angle theta.\n",
    "        \n",
    "        Args:\n",
    "            x: The input data. Shape (batch_size, num_coords, pos_dim (2)).\n",
    "            p: The latent poses. Shape (batch_size, num_latents, pos_dim (2) + theta (1)).\n",
    "        \"\"\"\n",
    "        # Compute the relative position between the input and the latent poses\n",
    "        rel_pos = x[:, :, None, :2] - p[:, None, :, :2]\n",
    "\n",
    "        # Get the orientation angle theta and convert to [cos(θ), sin(θ)]\n",
    "        theta = p[:, None, :, 2:]\n",
    "        cos_theta = jnp.cos(theta)\n",
    "        sin_theta = jnp.sin(theta)\n",
    "\n",
    "        # Compute the relative orientation between the input and the latent poses\n",
    "        invariant1 = rel_pos[..., 0] * cos_theta + rel_pos[..., 1] * sin_theta\n",
    "        invariant2 = -rel_pos[..., 0] * sin_theta + rel_pos[..., 1] * cos_theta\n",
    "        return jnp.stack([invariant1, invariant2], axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivariant Neural Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquivariantNeuralField(nn.Module):\n",
    "    \"\"\" Equivariant cross attention network for the latent points, conditioned on the poses.\n",
    "\n",
    "    Args:\n",
    "        num_hidden (int): The number of hidden units.\n",
    "        num_heads (int): The number of attention heads.\n",
    "        num_out (int): The number of output coordinates.\n",
    "        emb_freq_q (float): The frequency of the positional embedding for the query.\n",
    "        emb_freq_v (float): The frequency of the positional embedding for the value function.\n",
    "        nearest_k (int): The number of nearest latents to consider.\n",
    "        bi_invariant (Callable): The bi-invariant function to use.\n",
    "    \"\"\"\n",
    "    num_hidden: int\n",
    "    att_dim: int\n",
    "    num_heads: int\n",
    "    num_out: int\n",
    "    emb_freq_q: float\n",
    "    emb_freq_v: float\n",
    "    nearest_k: int\n",
    "    bi_invariant: Callable\n",
    "\n",
    "    def setup(self):\n",
    "        # Positional embedding that takes in relative positions.\n",
    "        self.pos_emb_q = nn.Sequential([PosEmb(self.num_hidden, self.emb_freq_q), nn.Dense(self.num_heads * self.att_dim)])\n",
    "        self.pos_emb_v = nn.Sequential([PosEmb(self.num_hidden, self.emb_freq_v), nn.Dense(2 * self.num_hidden)])\n",
    "\n",
    "        # Query, key, value functions.\n",
    "        self.W_k = nn.Dense(self.num_heads * self.att_dim)\n",
    "        self.W_v = nn.Dense(self.num_hidden)\n",
    "\n",
    "        # Value bi-linear conditioning function.\n",
    "        self.v = nn.Sequential([\n",
    "            nn.Dense(self.num_hidden),\n",
    "            nn.gelu,\n",
    "            nn.Dense(self.num_heads * self.num_hidden)])\n",
    "\n",
    "        # Output layer.\n",
    "        self.W_out = nn.Dense(self.num_out)\n",
    "\n",
    "    def __call__(self, x, p, c, g):\n",
    "        \"\"\" Apply equivariant cross attention.\n",
    "\n",
    "        Args:\n",
    "            x (jax.numpy.ndarray): The input coordinates. Shape (batch_size, num_coords, coord_dim).\n",
    "            p (jax.numpy.ndarray): The latent poses. Shape (batch_size, num_latents, coord_dim).\n",
    "            c (jax.numpy.ndarray): The latent context vectors. Shape (batch_size, num_latents, latent_dim).\n",
    "            g (jax.numpy.ndarray): The window size for the gaussian window. Shape (batch_size, num_latents, 1).\n",
    "        \"\"\"\n",
    "        # Calculate bi-invariants between input coordinates and latents\n",
    "        bi_inv = self.bi_invariant(x, p)\n",
    "        \n",
    "        # Calculate distances based on bi-invariant magnitude\n",
    "        zx_mag = jnp.sum(bi_inv ** 2, axis=-1)\n",
    "        nearest_z = jnp.argsort(zx_mag, axis=-1)[:, :, :self.nearest_k, None]\n",
    "\n",
    "        # Restrict the bi-invariants and context vectors to the nearest latents\n",
    "        zx_mag = jnp.take_along_axis(zx_mag[..., None], nearest_z, axis=2)\n",
    "        bi_inv = jnp.take_along_axis(bi_inv, nearest_z, axis=2)\n",
    "        k = jnp.take_along_axis(self.W_k(c)[:, None, :, :], nearest_z, axis=2)\n",
    "        v = jnp.take_along_axis(self.W_v(c)[:, None, :, :], nearest_z, axis=2)\n",
    "        g = jnp.take_along_axis(g[:, None, :, :], nearest_z, axis=2)\n",
    "\n",
    "        # Apply bi-invariant embedding for the query transform and conditioning of the value transform\n",
    "        q = self.pos_emb_q(bi_inv)\n",
    "        b_v, g_v = jnp.split(self.pos_emb_v(bi_inv), 2, axis=-1)\n",
    "        v = self.v(v * (1 + b_v) + g_v)\n",
    "\n",
    "        # Reshape to separate the heads\n",
    "        q = q.reshape(q.shape[:-1] + (self.num_heads, -1))\n",
    "        k = k.reshape(k.shape[:-1] + (self.num_heads, -1))\n",
    "        v = v.reshape(v.shape[:-1] + (self.num_heads, -1))\n",
    "\n",
    "        # Calculate the attention weights, apply gaussian mask based on bi-invariant magnitude, broadcasting over heads.\n",
    "        att_logits = ((q * k).sum(axis=-1, keepdims=True) / self.att_dim) - ((1 / g ** 2) * zx_mag)[..., None, :]\n",
    "        att = jax.nn.softmax(att_logits, axis=2)\n",
    "\n",
    "        # Attend the values to the queries and keys.\n",
    "        y = (att * v).sum(axis=2)\n",
    "\n",
    "        # Combine the heads and apply the output layer.\n",
    "        y = y.reshape(y.shape[:-2] + (-1,))\n",
    "        return self.W_out(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "\n",
    "Load the dataset, create coordinate grid, and initialize the ENF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home1/rvalperga/miniforge3/envs/enf/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/gpfs/home1/rvalperga/miniforge3/envs/enf/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n"
     ]
    }
   ],
   "source": [
    "# Load dataset, get sample image, create corresponding coordinates\n",
    "train_dloader, test_dloader = get_dataloader(config.dataset)\n",
    "sample = next(iter(train_dloader))\n",
    "img_shape = sample[0].shape[1:]\n",
    "\n",
    "# Random key for JAX operations\n",
    "key = jax.random.PRNGKey(55)\n",
    "\n",
    "# Create coordinate grid\n",
    "x = jnp.stack(jnp.meshgrid(jnp.linspace(-1, 1, img_shape[0]), jnp.linspace(-1, 1, img_shape[1])), axis=-1)\n",
    "x = jnp.reshape(x, (-1, 2))\n",
    "x = jnp.repeat(x[None, ...], config.dataset.batch_size, axis=0)\n",
    "\n",
    "# Define the model\n",
    "bi_inv = get_bi_invariant(config.enf.bi_invariant)\n",
    "model = EquivariantNeuralField(\n",
    "    num_hidden=config.enf.num_hidden,\n",
    "    att_dim=config.enf.att_dim,\n",
    "    num_heads=config.enf.num_heads,\n",
    "    num_out=config.enf.num_out,\n",
    "    emb_freq_q=config.enf.freq_multiplier_query,\n",
    "    emb_freq_v=config.enf.freq_multiplier_value,\n",
    "    nearest_k=config.enf.k_nearest,\n",
    "    bi_invariant=bi_inv,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model Parameters\n",
    "\n",
    "In JAX, we need to initialize model parameters by passing dummy inputs through the model so it can infer parameter shapes for JIT compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy latents for model initialization\n",
    "d_p = jnp.ones((config.dataset.batch_size, config.enf.num_latents, 2))                        # poses\n",
    "d_c = jnp.ones((config.dataset.batch_size, config.enf.num_latents, config.enf.latent_dim))    # context vectors\n",
    "d_g = jnp.ones((config.dataset.batch_size, config.enf.num_latents, 1))                        # gaussian window parameter\n",
    "\n",
    "# Initialize the model parameters\n",
    "enf_params = model.init(key, x, d_p, d_c, d_g)\n",
    "\n",
    "# Define optimizer for the ENF backbone\n",
    "enf_optimizer = optax.adam(learning_rate=config.optim.lr_enf)\n",
    "enf_opt_state = enf_optimizer.init(enf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Functions\n",
    "\n",
    "Define the inner loop and outer step functions for training. The inner loop optimizes the latent variables, while the outer step updates the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def inner_loop(enf_params, x_i, y_i, key):\n",
    "    # Sample poses\n",
    "    if config.enf.num_latents == 1:\n",
    "        poses = jnp.zeros((1, config.enf.num_latents, 2))\n",
    "    else: # Initialize poses in a grid\n",
    "        lims = 1 - 1 / math.sqrt(config.enf.num_latents)\n",
    "        poses = jnp.stack(jnp.meshgrid(jnp.linspace(-lims, lims, int(math.sqrt(config.enf.num_latents))),\n",
    "                                       jnp.linspace(-lims, lims, int(math.sqrt(config.enf.num_latents)))), axis=-1)\n",
    "        poses = jnp.reshape(poses, (1, -1, 2))\n",
    "    poses = poses.repeat(config.dataset.batch_size, axis=0)\n",
    "\n",
    "    # Add some noise to the poses\n",
    "    poses = poses + jax.random.normal(key, poses.shape) * 0.1 / jnp.sqrt(config.enf.num_latents)\n",
    "\n",
    "    # Initialize values for the poses, context and window\n",
    "    c = jnp.ones((x_i.shape[0], config.enf.num_latents, config.enf.latent_dim)) / config.enf.latent_dim  # context vectors\n",
    "    g = jnp.ones((x_i.shape[0], config.enf.num_latents, 1)) * 2 / jnp.sqrt(config.enf.num_latents)  # gaussian window parameter\n",
    "\n",
    "    def mse_loss(z, x_i, y_i):\n",
    "        out = model.apply(enf_params, x_i, *z)\n",
    "        return jnp.sum(jnp.mean((out - y_i) ** 2, axis=(1, 2)), axis=0)\n",
    "\n",
    "    loss, grads = jax.value_and_grad(mse_loss)((poses, c, g), x_i, y_i)\n",
    "\n",
    "    # Update the latent features\n",
    "    c = c - config.optim.inner_lr_c * grads[1]\n",
    "\n",
    "    # Update the poses if specific lr > 0\n",
    "    if config.optim.inner_lr_p > 0:\n",
    "        poses = poses - config.optim.inner_lr_p * grads[0]\n",
    "    if config.optim.inner_lr_g > 0:\n",
    "        g = g - config.optim.inner_lr_g * grads[2]\n",
    "\n",
    "    # Return loss with resulting latents\n",
    "    return mse_loss((poses, c, g), x_i, y_i), (poses, c, g)\n",
    "\n",
    "@jax.jit\n",
    "def outer_step(x_i, y_i, enf_params, enf_opt_state, key):\n",
    "    # Split key\n",
    "    key, new_key = jax.random.split(key)\n",
    "\n",
    "    # Perform inner loop optimization\n",
    "    (loss, _), grads = jax.value_and_grad(inner_loop, has_aux=True)(enf_params, x_i, y_i, key)\n",
    "\n",
    "    # Update the ENF backbone\n",
    "    enf_grads, enf_opt_state = enf_optimizer.update(grads, enf_opt_state)\n",
    "    enf_params = optax.apply_updates(enf_params, enf_grads)\n",
    "\n",
    "    # Return updated parameters and new key\n",
    "    return loss, enf_params, enf_opt_state, new_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Execute the training loop, periodically logging results and saving checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home1/rvalperga/miniforge3/envs/enf/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home1/rvalperga/miniforge3/envs/enf/lib/python3.11/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n",
      "/tmp/ipykernel_2702159/4013305820.py:2: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  return np.array(image, dtype=np.float32) / 255\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m y \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mreshape(img, (img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Perform outer loop optimization\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m loss, enf_params, enf_opt_state, key \u001b[38;5;241m=\u001b[39m \u001b[43mouter_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menf_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menf_opt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m epoch_loss\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     15\u001b[0m glob_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(_cls, count, mu, nu)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "glob_step, lowest_loss = 0, jnp.inf\n",
    "for epoch in range(config.train.num_epochs):\n",
    "    epoch_loss = []\n",
    "    for i, batch in tqdm(enumerate(train_dloader), total=len(train_dloader), desc=f'Epoch {epoch}'):\n",
    "        # Unpack batch, flatten img\n",
    "        img = batch[0]\n",
    "        y = jnp.reshape(img, (img.shape[0], -1, img.shape[-1]))\n",
    "\n",
    "        # Perform outer loop optimization\n",
    "        loss, enf_params, enf_opt_state, key = outer_step(\n",
    "            x, y, enf_params, enf_opt_state, key)\n",
    "\n",
    "        epoch_loss.append(loss)\n",
    "        glob_step += 1\n",
    "\n",
    "        if glob_step % config.train.log_interval == 0:\n",
    "            # Reconstruct and log an image, perform inner loop\n",
    "            _, (p_b, c, g) = inner_loop(enf_params, x, y, key)\n",
    "\n",
    "            # Reconstruct image\n",
    "            img_r = model.apply(enf_params, x, p_b, c, g)[0]\n",
    "\n",
    "            # Min max normalization\n",
    "            min_val = jnp.min(img[0])\n",
    "            max_val = jnp.max(img[0])\n",
    "\n",
    "            img_r = (img_r - jnp.min(img_r)) / (jnp.max(img_r) - jnp.min(img_r))\n",
    "            img = (img - min_val) / (max_val - min_val)\n",
    "\n",
    "            print(img.min(), img.max(), img_r.min(), img_r.max())\n",
    "\n",
    "            # Plot the original and reconstructed image\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(131)\n",
    "            plt.imshow(jnp.reshape(img[0], (img_shape)))\n",
    "            plt.title(\"Original\")\n",
    "            plt.axis('off')\n",
    "            plt.subplot(132)\n",
    "            plt.imshow(jnp.reshape(img_r, (img_shape)))\n",
    "            plt.title(\"Reconstructed\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Plot the poses\n",
    "            plt.subplot(133)\n",
    "            plt.imshow(jnp.reshape(img_r, (img_shape)))\n",
    "            plt.title(\"Poses\")\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Poses are [-1, 1], map to [0, img_shape]\n",
    "            poses_m = (p_b + 1) / 2 * img_shape[0]\n",
    "            plt.scatter(poses_m[0, :, 0], poses_m[0, :, 1], c='r')\n",
    "            plt.close('all')\n",
    "            # Save checkpoint if lowest loss\n",
    "            if sum(epoch_loss) / len(epoch_loss) < lowest_loss:\n",
    "                lowest_loss = sum(epoch_loss) / len(epoch_loss)\n",
    "\n",
    "                # checkpoint_manager.save(step=epoch, args=ocp.args.Composite(\n",
    "                #     state=ocp.args.StandardSave(enf_params),\n",
    "                #     config=ocp.args.JsonSave(config.to_dict())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
